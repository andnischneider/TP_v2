---
title: "dada2 preprocessing of 2012 ITS data"
author: "Andreas Schneider"
date: "18/07/2019"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r import}
suppressMessages(library(here)) 
suppressMessages(library(dada2))
suppressMessages(library(ShortRead))
suppressMessages(library(Biostrings))
```

# Introduction

The data will be imported into R and clustered to ASV (amplicon sequencing variants) with the help of the dada2 R package.

Crucial difference of ITS compared to 16S: the ITS region is highly variable in length (due to fast mutation rate), and thus shouldn't be truncated at one length like the 16S region.

### Needles

```{r ITS_Needles }
path_n_i <- here("data/ITS/Needles/DeML_pooled/")

fnFs_n_i <- sort(list.files(path_n_i, pattern = "R1.fastq.gz", full.names = TRUE))
fnRs_n_i <- sort(list.files(path_n_i, pattern = "R2.fastq.gz", full.names = TRUE))
```

First we check for primers in the data (I think the primers were already removed in theses datasets, but we check just to make sure). First we record their DNA sequences.

```{r}
ITS1f <- "CTTGGTCATTTAGAGGAAGTAA"
ITS2 <- "GCTGCGTTCTTCATCGATGC"
```

Next we create a vector with all possible orientations of the primers

```{r}
allOrients <- function (primer) {
  require(Biostrings)
  dna <- DNAString(primer)
  orients <- c(Forward = dna, Complement = complement(dna), 
               Reverse = reverse(dna), RevComp = reverseComplement(dna))
  return(sapply(orients, toString))
}
ITS1f.orients <- allOrients(ITS1f)
ITS2.orients <- allOrients(ITS2)
```

The presence of ambiguous bases (Ns) in the sequencing reads makes accurate mapping of short primer sequences difficult. Next we are going to “pre-filter” the sequences just to remove those with Ns, but perform no other filtering.

```{r cache=TRUE}
fnFs_n_i.filtN <- file.path(path_n_i, "filtN", basename(fnFs_n_i))
fnRs_n_i.filtN <- file.path(path_n_i, "filtN", basename(fnRs_n_i))
filterAndTrim(fnFs_n_i, fnFs_n_i.filtN, fnRs_n_i, fnRs_n_i.filtN, maxN = 0, multithread = TRUE)
```

Now we can count the number of times the primer sequences appear in the samples.

```{r cache=TRUE}
primerHits <- function (primer, fn) {
  nhits <- vcountPattern(primer, sread(readFastq(fn)), fixed = FALSE)
  return(sum(nhits > 0))
}
rbind(FWD.ForwardReads = sapply(ITS1f.orients, primerHits, fn = fnFs_n_i.filtN[[1]]),
      FWD.ReverseReads = sapply(ITS1f.orients, primerHits, fn = fnRs_n_i.filtN[[1]]),
      REV.ForwardReads = sapply(ITS2.orients, primerHits, fn = fnFs_n_i.filtN[[1]]),
      REV.ReverseReads = sapply(ITS2.orients, primerHits, fn = fnRs_n_i.filtN[[1]]))
```

There are a few hits after all, so we proceed with the cutting step.

```{r}
cutadapt <- "/mnt/picea/home/aschneider/.conda/envs/amp_seq/bin/cutadapt"
system2(cutadapt, args = "--version")
```

```{r cache=TRUE,include=FALSE}
path.cut <- file.path(path_n_i, "cutadapt")
if(!dir.exists(path.cut)) dir.create(path.cut)
fnFs_n_i.cut <- file.path(path.cut, basename(fnFs_n_i))
fnRs_n_i.cut <- file.path(path.cut, basename(fnRs_n_i))

ITS1f.rc <- rc(ITS1f)
ITS2.rc <- rc(ITS2)

#Trim FWD and revcomp of REV off of R1
R1.flags <- paste("-g", ITS1f, "-a", ITS2.rc)
#Trim rev and rc of fw off of R2
R2.flags <- paste("-G", ITS2, "-A", ITS1f.rc)
#Run Cutadapt
for (i in seq_along(fnFs_n_i)) {
  system2(cutadapt, args = c(R1.flags, R2.flags, 
                             "-n", 2,
                             "--minimum-length", 50,
                             "-o", fnFs_n_i.cut[i],
                             "-p", fnRs_n_i.cut[i],
                             fnFs_n_i.filtN[i],
                             fnRs_n_i.filtN[i]))
}

rbind(FWD.ForwardReads = sapply(ITS1f.orients, primerHits, fn = fnFs_n_i.cut[[1]]),
      FWD.ReverseReads = sapply(ITS1f.orients, primerHits, fn = fnRs_n_i.cut[[1]]),
      REV.ForwardReads = sapply(ITS2.orients, primerHits, fn = fnFs_n_i.cut[[1]]),
      REV.ReverseReads = sapply(ITS2.orients, primerHits, fn = fnRs_n_i.cut[[1]]))
```
The sanity check looks good, all primer sequences have been removed from the data.

Now we can proceed. We start with extracting the sample names and plotting Quality profiles for the first 4 samples.

```{r cache=TRUE}
sample.names_n_i <- sapply(strsplit(basename(fnFs_n_i.cut), "_"), `[`, 1)

plotQualityProfile(fnFs_n_i.cut[1:4])
plotQualityProfile(fnRs_n_i.cut[1:4])
```

Next is the filtering and trimming.

```{r}
filtFs_n_i <- file.path(path_n_i, "filtered_F", basename(fnFs_n_i.cut))
filtRs_n_i <- file.path(path_n_i, "filtered_R", basename(fnRs_n_i.cut))
```
The dada2 recommends the following (standard) parameters for the filtering.
```{r cache=TRUE}
out_n_i <- filterAndTrim(fnFs_n_i.cut, filtFs_n_i, fnRs_n_i.cut, filtRs_n_i, maxN = 0, 
                         maxEE = c(6,6), truncQ = 2, minLen = 50, rm.phix = TRUE, 
                         compress = TRUE, multithread = TRUE)

head(out_n_i, n = 10)
```
Since the overall read quality is quite bad we had to go up to 6 with the mEE parameter to retain a decent number of reads.

The next steps (learning errors and the dada2 algorithm) are run from the command line again.

#### Chimera removal

```{r}
seq.tab_n_i <- readRDS("data/ITS/Needles/dada2/seqtab.rds")
seq.tab_n_i.nochim <- removeBimeraDenovo(seq.tab_n_i, method = "consensus",
                                       multithread= TRUE, verbose = TRUE)
saveRDS(seq.tab_n_i.nochim, "data/ITS/Needles/dada2/seqtab_nochim.rds")

#Import dada_files
dadaFs_n_i <- readRDS("data/ITS/Needles/dada2/dada_f.rds")
dadaRs_n_i <- readRDS("data/ITS/Needles/dada2/dada_r.rds")
#mergers_n_i <- mergePairs(dadaFs_n_i, filtFs_n_i, dadaRs_n_i, filtRs_n_i, verbose = TRUE, maxMismatch = 1)

#track the reads through pipeline
track_n_i <- cbind(out_n_i, sapply(dadaFs_n_i, getN), sapply(dadaRs_n_i, getN), rowSums(seq.tab_n_i), rowSums(seq.tab_n_i.nochim))
colnames(track_n_i) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track_n_i) <- sample.names_n_i
head(track_n_i, n = 15)
```

#### Writing of sequence fasta for ITSx

```{r}
dna_n_i <- DNAStringSet(colnames(seq.tab_n_i.nochim))
names(dna_n_i) <- paste0("ASV", seq(ncol(seq.tab_n_i.nochim)))
writeXStringSet(dna_n_i, file = "data/ITS/Roots/phyloseq/refseq.fa")
```


### Roots

```{r ITS_Roots }
path_r_i <- here("data/ITS/Roots/DeML_pooled/")

fnFs_r_i <- sort(list.files(path_r_i, pattern = "R1.fastq.gz", full.names = TRUE))
fnRs_r_i <- sort(list.files(path_r_i, pattern = "R2.fastq.gz", full.names = TRUE))
```

First we check for primers in the data (I think the primers were already removed in theses datasets, but we check just to make sure).

The presence of ambiguous bases (Ns) in the sequencing reads makes accurate mapping of short primer sequences difficult. Next we are going to “pre-filter” the sequences just to remove those with Ns, but perform no other filtering.

```{r cache=TRUE}
fnFs_r_i.filtN <- file.path(path_r_i, "filtN", basename(fnFs_r_i))
fnRs_r_i.filtN <- file.path(path_r_i, "filtN", basename(fnRs_r_i))
filterAndTrim(fnFs_r_i, fnFs_r_i.filtN, fnRs_r_i, fnRs_r_i.filtN, maxN = 0, multithread = TRUE)
```

Now we can count the number of times the primer sequences appear in the samples.

```{r cache=TRUE}

rbind(FWD.ForwardReads = sapply(ITS1f.orients, primerHits, fn = fnFs_r_i.filtN[[1]]),
      FWD.ReverseReads = sapply(ITS1f.orients, primerHits, fn = fnRs_r_i.filtN[[1]]),
      REV.ForwardReads = sapply(ITS2.orients, primerHits, fn = fnFs_r_i.filtN[[1]]),
      REV.ReverseReads = sapply(ITS2.orients, primerHits, fn = fnRs_r_i.filtN[[1]]))
```

There are a few hits after all, so we proceed with the cutting step.

```{r cache=TRUE,include=FALSE}
path.cut_r <- file.path(path_r_i, "cutadapt")
if(!dir.exists(path.cut_r)) dir.create(path.cut_r)
fnFs_r_i.cut <- file.path(path.cut_r, basename(fnFs_r_i))
fnRs_r_i.cut <- file.path(path.cut_r, basename(fnRs_r_i))

#Run Cutadapt
for (i in seq_along(fnFs_r_i)) {
  system2(cutadapt, args = c(R1.flags, R2.flags, 
                             "-n", 2,
                             "--minimum-length", 50,
                             "-o", fnFs_r_i.cut[i],
                             "-p", fnRs_r_i.cut[i],
                             fnFs_r_i.filtN[i],
                             fnRs_r_i.filtN[i]))
}

rbind(FWD.ForwardReads = sapply(ITS1f.orients, primerHits, fn = fnFs_r_i.cut[[1]]),
      FWD.ReverseReads = sapply(ITS1f.orients, primerHits, fn = fnRs_r_i.cut[[1]]),
      REV.ForwardReads = sapply(ITS2.orients, primerHits, fn = fnFs_r_i.cut[[1]]),
      REV.ReverseReads = sapply(ITS2.orients, primerHits, fn = fnRs_r_i.cut[[1]]))
```
The sanity check looks good, all primer sequences have been removed from the data.

Now we can proceed as with the 16S data. We start with extracting the sample names and plotting Quality profiles for the first 4 samples.

```{r cache=TRUE}
sample.names_r_i <- sapply(strsplit(basename(fnFs_r_i.cut), "_"), `[`, 1)

plotQualityProfile(fnFs_r_i.cut[1:4])
plotQualityProfile(fnRs_r_i.cut[1:4])


```

Looks better than the needles. Next is the filtering and trimming.

```{r}
filtFs_r_i <- file.path(path_r_i, "filtered_F", basename(fnFs_r_i.cut))
filtRs_r_i <- file.path(path_r_i, "filtered_R", basename(fnRs_r_i.cut))
```
The dada2 recommends the following (standard) parameters for the filtering. `maxEE` was changed to 6, otherwise we lose too much data.
```{r cache=TRUE}
out_r_i <- filterAndTrim(fnFs_r_i.cut, filtFs_r_i, fnRs_r_i.cut, filtRs_r_i, maxN = 0, 
                         maxEE = c(6,6), truncQ = 2, minLen = 50, rm.phix = TRUE, 
                         compress = TRUE, multithread = TRUE)

head(out_r_i, n = 10)

```

Denoising and merging ran on SLURM.

#### Chimera removal

```{r}
seq.tab_r_i <- readRDS("data/ITS/Roots/dada2/seqtab.rds")
seq.tab_r_i.nochim <- removeBimeraDenovo(seq.tab_r_i, method = "consensus",
                                       multithread= TRUE, verbose = TRUE)
saveRDS(seq.tab_r_i.nochim, "data/ITS/Roots/dada2/seqtab_nochim.rds")

#Import dada_files
dadaFs_r_i <- readRDS("data/ITS/Roots/dada2/dada_f.rds")
dadaRs_r_i <- readRDS("data/ITS/Roots/dada2/dada_r.rds")
#mergers_r_i <- mergePairs(dadaFs_r_i, filtFs_r_i, dadaRs_r_i, filtRs_r_i, verbose = TRUE, maxMismatch = 1)

#track the reads through pipeline
track_r_i <- cbind(out_r_i, sapply(dadaFs_r_i, getN), sapply(dadaRs_r_i, getN), rowSums(seq.tab_r_i), rowSums(seq.tab_r_i.nochim))
colnames(track_r_i) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track_r_i) <- sample.names_r_i
head(track_r_i, n = 15)
```

#### Writing of sequence fasta for ITSx

```{r}
dna_r_i <- DNAStringSet(colnames(seq.tab_r_i.nochim))
names(dna_r_i) <- paste0("ASV", seq(ncol(seq.tab_r_i.nochim)))
writeXStringSet(dna_r_i, file = "data/ITS/Roots/phyloseq/refseq.fa")
```
