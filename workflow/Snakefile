include: "rules/common.smk"

rule all:
    """
    Collect the main outputs of the workflow
    """
    input:
        opj(config["results_dir"], "itsx",
            "itsx.{its_type}.fasta".format(its_type=config["its"]["type"]))

rule fastq_dump:
    output:
        R1 = opj(config["data_dir"], "{dirname}", "{sample_id}_1.fastq.gz"),
        R2 = opj(config["data_dir"], "{dirname}", "{sample_id}_2.fastq.gz")
    log:
        opj(config["results_dir"], "logs", "{dirname}", "sra-tools", "{sample_id}.log")
    params:
        data_dir = lambda wildcards, output: os.path.dirname(output.R1),
        acc = lambda wildcards: samples[wildcards.dirname][wildcards.sample_id]["acc"],
        spots = config["spots"]
    conda:
        "envs/sratools.yml"
    shell:
        """
        fastq-dump {params.spots} --split-3 --gzip -O {params.data_dir} \
            {params.acc} > {log} 2>&1
        mv {params.data_dir}/{params.acc}_1.fastq.gz {output.R1}
        mv {params.data_dir}/{params.acc}_2.fastq.gz {output.R2}
        """

def symlink(input, output):
    from os.path import abspath
    from os import symlink
    src = abspath(input)
    dst = abspath(output)
    symlink(src, dst)

rule link:
    input:
        lambda wildcards: samples[wildcards.dirname][wildcards.sample_id][wildcards.R]
    output:
        opj(config["results_dir"], "{dirname}", "{sample_id}_R{R}.fastq.gz")
    run:
        symlink(input, output)

rule prefilter:
    """Runs the ITS prefiltering step for ambiguous bases"""
    input:
        R1 = lambda wildcards: samples[wildcards.dirname][wildcards.sample_id]["R1"],
        R2 = lambda wildcards: samples[wildcards.dirname][wildcards.sample_id]["R2"]
    output:
        R1 = opj(config["results_dir"], "{dirname}", "prefilter", "{sample_id}_R1.fastq.gz"),
        R2 = opj(config["results_dir"], "{dirname}", "prefilter", "{sample_id}_R2.fastq.gz"),
        rds = opj(config["results_dir"], "{dirname}", "prefilter", "{sample_id}.rds")
    log:
        opj(config["results_dir"], "logs", "{dirname}", "prefilter", "{sample_id}.log")
    threads: config["threads"]
    conda:
        "envs/dada2.yml"
    script:
        "scripts/filter.R"

rule generate_revcomp:
    output:
        fwd_rc = temp(opj(config["results_dir"], "intermediate", "fwd_rc")),
        rev_rc = temp(opj(config["results_dir"], "intermediate", "rev_rc"))
    params:
        fwd = config["cutadapt"]["FWD"],
        rev = config["cutadapt"]["REV"]
    conda:
        "envs/biopython.yml"
    shell:
        """
        python workflow/scripts/revcomp.py {params.fwd} > {output.fwd_rc}
        python workflow/scripts/revcomp.py {params.rev} > {output.rev_rc}
        """

rule cut_ITS_primers:
    """Removes primers from ITS data using cutadapt"""
    input:
        R1 = opj(config["results_dir"], "intermediate", "prefilter", "{pool_id}_R1.fastq.gz"),
        R2 = opj(config["results_dir"], "intermediate", "prefilter", "{pool_id}_R2.fastq.gz"),
        fwd_rc = opj(config["results_dir"], "intermediate", "fwd_rc"),
        rev_rc = opj(config["results_dir"], "intermediate", "rev_rc")
    output:
        R1 = opj(config["results_dir"], "intermediate", "cutadapt", "{pool_id}_R1.fastq.gz"),
        R2 = opj(config["results_dir"], "intermediate", "cutadapt", "{pool_id}_R2.fastq.gz")
    log:
        opj(config["results_dir"], "logs", "cutadapt", "{pool_id}.log")
    params:
        FWD = config["cutadapt"]["FWD"],
        REV = config["cutadapt"]["REV"],
        n = config["cutadapt"]["n"],
        min_len = config["cutadapt"]["minimum_length"]
    threads: config["threads"]
    conda:
        "envs/cutadapt.yml"
    shell:
        """
        A=$(cat {input.fwd_rc})
        a=$(cat {input.rev_rc})
        
        cutadapt -g {params.FWD} -a $a -G {params.REV} -A $A -j {threads} \
         -n {params.n} -o {output.R1} -p {output.R2} --minimum-length {params.min_len} \
         {input.R1} {input.R2} > {log} 2>&1
        """

rule filterAndTrim:
    input:
        R1 = opj(config["results_dir"], "intermediate", "cutadapt", "{pool_id}_R1.fastq.gz"),
        R2 = opj(config["results_dir"], "intermediate", "cutadapt", "{pool_id}_R2.fastq.gz")
    output:
        R1 = opj(config["results_dir"], "intermediate", "filtertrim", "R1", "{pool_id}_R1.fastq.gz"),
        R2 = opj(config["results_dir"], "intermediate", "filtertrim", "R2", "{pool_id}_R2.fastq.gz"),
        rds = opj(config["results_dir"], "intermediate", "filtertrim", "{pool_id}.rds")
    log:
        opj(config["results_dir"], "logs", "filtertrim", "{pool_id}.log")
    threads: config["threads"]
    conda:
        "envs/dada2.yml"
    params:
        maxN = config["dada2"]["maxN"],
        truncQ = config["dada2"]["truncQ"],
        truncLen = config["dada2"]["truncLen"],
        maxEE = config["dada2"]["maxEE"],
        minLen = config["dada2"]["minLen"]
    script:
        "scripts/filter.R"

rule dada2:
    """Calls DADA2 Rscript with trimmed input"""
    input:
        expand(opj(config["results_dir"], "intermediate", "filtertrim", "R1",
                         "{pool_id}_R1.fastq.gz"),
                     pool_id = pools.keys()),
        expand(opj(config["results_dir"], "intermediate", "filtertrim", "R2",
                         "{pool_id}_R2.fastq.gz"),
                     pool_id = pools.keys())
    output:
        expand(opj(config["results_dir"], "dada2", "{f}.rds"),
               f=["dada_f", "dada_r", "mergers", "seqtab", "seqtab_nc"]),
        opj(config["results_dir"], "dada2", "seqs.fasta")
    log:
        opj(config["results_dir"], "logs", "dada2", "dada2.log")
    params:
        fw_dir = opj(config["results_dir"], "intermediate", "filtertrim", "R1"),
        rv_dir = opj(config["results_dir"], "intermediate", "filtertrim", "R2"),
        out_dir = opj(config["results_dir"], "dada2")
    resources:
        runtime = lambda wildcards, attempt: attempt**2*60*48,
        mem_mb = 64000
    threads: 8
    conda:
        "envs/dada2.yml"
    shell:
        """
        Rscript --vanilla workflow/scripts/runDada2.R {params.fw_dir} {params.rv_dir} \
            {params.out_dir} {threads} > {log} 2>&1
        """

rule itsx:
    input:
        opj(config["results_dir"], "dada2", "seqs.fasta")
    output:
        expand(opj(config["results_dir"], "itsx", "itsx.{suffix}"),
               suffix = ["{}.fasta".format(config["its"]["type"]),
                         "graph","positions.txt","problematic.txt",
                         "summary.txt"])
    log:
        opj(config["results_dir"], "logs", "itsx", "itsx.log")
    params:
        prefix=lambda wildcards, output: os.path.dirname(output[0])
    conda:
        "envs/itsx.yml"
    threads: 4
    shell:
         """
         ITSx -i {input} -o {params.prefix}/itsx --cpu {threads} --multi_thread T \
            --preserve T --partial --minlen 50 > {log} 2>&1
         """

rule process_itsx:
    input:
        seqtab = opj(config["results_dir"], "dada2", "seqtab_nc.rds"),
        its_out = opj(config["results_dir"], "itsx",
                      "itsx.{its_type}.fasta".format(its_type=config["its"]["type"])),
        its_in = opj(config["results_dir"], "dada2", "seqs.fasta")
    output:
        opj(config["results_dir"], "itsx", "seqtab.nc_itsx_clean.rds")
    log:
        opj(config["results_dir"], "logs", "itsx", "process_itsx.log")
    conda:
        "envs/dada2.yml"
    threads: 4
    shell:
        """
        Rscript --vanilla workflow/scripts/ProcessITSx.R {input.its_in} \
            {input.its_out} {input.seqtab} {output} {threads} > {log} 2>&1
        """